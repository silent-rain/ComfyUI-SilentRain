[workspace]
resolver = "2"
members = ["apps/comfy_app", "apps/llama_cpp_core", "apps/server", "apps/web"]


[profile.dev]
debug = false # 关闭调试日志, 加快构建速度


[workspace.dependencies]
# python
pyo3 = "0.27.2"
# pyo3-async-runtimes = "0.26.0"
# pyo3-log = "0.12"    # 从 Rust 到 Python 日志记录的桥梁
# pyo3-arrow = "0.12" # pyo3 的轻量级Apache Arrow集成。
# pyo3-bytes = "0.4"   # bytes 转换
pythonize = "0.27.0" # Serde 序列化器，用于将 Rust 对象转换为 JSON 兼容的 Python 对象
numpy = "0.27.1"     # rust-numpy
# dict_derive = "0.6"  # Derive FromPyObject 自动将 Python 字典转换为 Rust 结构体


# web
wasm-bindgen = "0.2"
wasm-bindgen-futures = "0.4"
serde-wasm-bindgen = "0.6"
wasm-bindgen-test = "0.3"
js-sys = "0.3"
web-sys = "0.3"


serde = "1.0"                            # 用于序列化和反序列化
serde_json = "1.0"                       # 用于序列化和反序列化
serde_repr = "0.1"                       # 自动将枚举的变体序列化为对应的数字
strum = "0.27"                           # 用于枚举的宏
strum_macros = "0.27"                    # 用于枚举的宏
rust_decimal = "1.40"                    # 用于处理十进制数字的库, 适用于需要有效整数和小数位且无舍入误差的财务计算
raw-string = "0.3"
walkdir = "2.5"                          # 用于遍历目录树
chardet = "0.2"                          # 用于检测文本编码的库
encoding = "0.2"                         # 用于编码和解码文本的库
encoding_rs = "0.8"                      # 用于编码和解码文本的库
rand = "0.9"                             # 用于生成随机数
rand_chacha = "0.10"                     # 用于生成随机数
lazy_static = "1.5"                      # 用于延迟初始化全局变量
reqwest = "0.13"                         # 用于 HTTP 客户端
regex = "1.12"                           # 正则表达式
base64 = "0.22"                          # 用于 base64 编码解码
rust-embed = "8.11"                      # 用于将静态文件嵌入到二进制文件中
tempfile = "3.24"                        # 用于创建临时文件和目录
crc32fast = "1.5"                        # 快速、SIMD加速的CRC32（IEEE）校验和计算
futures = "0.3"                          # 用于异步编程
tokio = "1.43"                           # 异步运行时
async-trait = "0.1"                      # 异步 trait
dashmap = "6.1"                          # 并发 HashMap
parking_lot = "0.12"                     # 更高效的锁
indexmap = "2.13"                        # 有序的 HashMap
infer = "0.19"                           # 推断文件和MIME类型的轻量级工具
uuid = "1.20"
async-openai = "0.32"
open-ai-rust-responses-by-sshift = "0.4.3"

anyhow = "1.0"
thiserror = "2.0"

log = "0.4"
tracing = "0.1"
tracing-subscriber = "0.3"
tracing-log = "0.2"

candle-core = "0.9"
candle-nn = "0.9"
candle-onnx = "0.9"
candle-transformers = "0.9"
candle-flash-attn = "0.9"   # 用于 Flash Attention
candle-kernels = "0.9"
hf-hub = "0.4"              # 与 huggingface hub 集成
tokenizers = "0.22"         # 标记文本
parquet = "57.2"            # 列式存储数据文件格式
image = "0.25"
png = "0.18"                # 用于读取和写入 PNG 图像
ndarray = "0.17"            # 用于多维数组
# llama-cpp-2 = "0.1.133"     # llama.cpp 的封装
# llama-cpp-2 = { git = "https://github.com/utilityai/llama-cpp-rs", branch = "main" }
llama-cpp-2 = { git = "https://github.com/utilityai/llama-cpp-rs", tag = "0.1.133" }
ort = "=2.0.0-rc.10"                                                                 # ONNX Runtime

# src
intel-mkl-src = "0.8"  # 为 Intel/AMD 平台提供行业领先的数学计算性能，适合高性能计算场景
accelerate-src = "0.3" # 为 Apple 设备提供原生硬件加速，优化能效比
